{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e424e8-3cc0-4a93-87ab-ff2afea13dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/27 15:29:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2024-04-27 15:29:...|6711211621056771738|2707077687595228535|               true|\n",
      "|2024-04-27 15:27:...|2707077687595228535|8059457254979550641|               true|\n",
      "|2024-04-27 15:26:...|8059457254979550641|4316376306380043017|               true|\n",
      "|2024-04-27 15:25:...|4316376306380043017|6945889682975321469|               true|\n",
      "|2024-04-27 15:25:...|6945889682975321469|2500024997980005591|               true|\n",
      "|2024-04-27 15:23:...|2500024997980005591|9015970749471366070|               true|\n",
      "|2024-04-27 15:13:...|9015970749471366070|1036892303015044680|               true|\n",
      "|2024-04-27 15:11:...|1036892303015044680|3663590870506627609|               true|\n",
      "|2024-04-27 13:29:...|3663590870506627609| 922663229200831164|               true|\n",
      "|2024-04-27 13:28:...| 922663229200831164|9220030009765536769|               true|\n",
      "|2024-04-27 10:37:...|9220030009765536769|2195253128215160933|               true|\n",
      "|2024-04-27 10:36:...|2195253128215160933|               NULL|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "6711211621056771738 4316376306380043017\n",
      "Data with new schema:\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+----------+---------------+\n",
      "| Age|Cabin|Embarked|   Fare|                Name|Parch|PassengerId|Pclass|   Sex|SibSp|Survived|          Ticket|Title|Family_Size|new_column|choose_a_column|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+----------+---------------+\n",
      "|77.0|    a|       b|   77.0|                 ccc|    1|          2|     3|     M|    4|    77.0|               a|    b|          4|     lorem|           NULL|\n",
      "|77.0|    a|       b|   77.0|                 ccc|    1|          2|     3|     M|    4|    77.0|               a|    b|          4|     lorem|           NULL|\n",
      "|22.0| NULL|       S|   7.25|Braund, Mr. Owen ...|    0|          1|     3|  male|    1|     0.0|       A/5 21171|   Mr|          1|      NULL|           NULL|\n",
      "|38.0|  C85|       C|71.2833|Cumings, Mrs. Joh...|    0|          2|     1|female|    1|     1.0|        PC 17599|  Mrs|          1|      NULL|           NULL|\n",
      "|26.0| NULL|       S|  7.925|Heikkinen, Miss. ...|    0|          3|     3|female|    0|     1.0|STON/O2. 3101282| Miss|          0|      NULL|           NULL|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Data with old schema:\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+\n",
      "| Age|Cabin|Embarked|   Fare|                Name|Parch|PassengerId|Pclass|   Sex|SibSp|Survived|          Ticket|Title|Family_Size|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+\n",
      "|22.0| NULL|       S|   7.25|Braund, Mr. Owen ...|    0|          1|     3|  male|    1|     0.0|       A/5 21171|   Mr|          1|\n",
      "|38.0|  C85|       C|71.2833|Cumings, Mrs. Joh...|    0|          2|     1|female|    1|     1.0|        PC 17599|  Mrs|          1|\n",
      "|26.0| NULL|       S|  7.925|Heikkinen, Miss. ...|    0|          3|     3|female|    0|     1.0|STON/O2. 3101282| Miss|          0|\n",
      "|35.0| C123|       S|   53.1|Futrelle, Mrs. Ja...|    0|          4|     1|female|    1|     1.0|          113803|  Mrs|          1|\n",
      "|35.0| NULL|       S|   8.05|Allen, Mr. Willia...|    0|          5|     3|  male|    0|     0.0|          373450|   Mr|          0|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/27 15:29:35 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the absolute paths to the Iceberg tables and JAR files\n",
    "iceberg_tables_path = \"/Users/france.cama/code/iceberg-practice/iceberg_tables\"\n",
    "iceberg_jars_path = \"/Users/france.cama/code/iceberg-practice/jars/iceberg-spark-runtime-3.5_2.13-1.5.0.jar\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg schema evolution feature\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dderby.system.home=\" + iceberg_tables_path) \\\n",
    "    .config(\"spark.jars\", iceberg_jars_path) \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.warehouse\", iceberg_tables_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sql(\"ALTER TABLE titanic DROP COLUMN choose_a_column;\")\n",
    "\n",
    "# Add a new column to the schema\n",
    "spark.sql(\"ALTER TABLE titanic ADD COLUMN choose_a_column string\")\n",
    "spark.sql(\"INSERT INTO default.titanic VALUES (77, 'a', 'b', 77, 'ccc', 1, 2, 3, 'M', 4, 77, 'a', 'b', 4, 'lorem', 'lorem');\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic.history ORDER BY made_current_at DESC;\").show()\n",
    "\n",
    "current_snapshot_id = spark.sql(\"SELECT snapshot_id FROM default.titanic.history ORDER BY made_current_at DESC;\").first()[0]\n",
    "second_snapshot_id = spark.sql(\"SELECT snapshot_id FROM default.titanic.history ORDER BY made_current_at DESC LIMIT 1 OFFSET 3;\").first()[0]\n",
    "\n",
    "print(current_snapshot_id, second_snapshot_id )\n",
    "\n",
    "# Read the table with the new schema\n",
    "df = spark.sql(f\"SELECT * FROM titanic VERSION AS OF {current_snapshot_id};\")\n",
    "print(\"Data with new schema:\")\n",
    "df.show(5)\n",
    "\n",
    "# Read the table with the old schema\n",
    "df_old = spark.sql(f\"SELECT * FROM titanic VERSION AS OF 9220030009765536769;\")\n",
    "print(\"Data with old schema:\")\n",
    "df_old.show(5)\n",
    "\n",
    "#spark.sql(\"ALTER TABLE titanic DROP COLUMN choose_a_column;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74025246-e1a0-474c-856a-89da3a9bddb2",
   "metadata": {},
   "source": [
    "It's possible to alter the schema of the table and depending on the snapshot you want to access the schema is determined, allowing yo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
