{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c8a5d4-d21d-419d-9e2c-bd2a3841ed32",
   "metadata": {},
   "source": [
    "For controlling metadata size and storage costs, Iceberg provides snapshot lifecycle management procedures such as expire_snapshots and other table management techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10056d8-0bb3-4dae-b8c9-9c6ccbecc105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/22 18:49:05 WARN Utils: Your hostname, MBA-Francesco.local resolves to a loopback address: 127.0.0.1; using 192.168.1.62 instead (on interface en0)\n",
      "24/07/22 18:49:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/07/22 18:49:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2024-07-22 11:47:...|6609739537041086161|1184812391625634863|               true|\n",
      "|2024-07-22 12:22:...|2309543119036033141|6609739537041086161|              false|\n",
      "|2024-07-22 12:23:...|6609739537041086161|1184812391625634863|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "Branches of the table. If none has been created: just the main branch is printed which points at the selected version/snapshot of the table\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                name|  type|        snapshot_id|max_reference_age_in_ms|min_snapshots_to_keep|max_snapshot_age_in_ms|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                main|BRANCH|6609739537041086161|                   NULL|                 NULL|                  NULL|\n",
      "|yearly_snapshots_10y|BRANCH|6609739537041086161|           315360000000|                   10|                  NULL|\n",
      "|            EOY_2024|   TAG|6609739537041086161|             2592000000|                 NULL|                  NULL|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "\n",
      "Done!\n",
      "+----+-----+--------+----+--------------------+-----+-----------+------+----+-----+--------+---------+-----+-----------+---------------+-------+\n",
      "| Age|Cabin|Embarked|Fare|                Name|Parch|PassengerId|Pclass| Sex|SibSp|Survived|   Ticket|Title|Family_Size|choose_a_column|new_col|\n",
      "+----+-----+--------+----+--------------------+-----+-----------+------+----+-----+--------+---------+-----+-----------+---------------+-------+\n",
      "|77.0|    a|       b|77.0|                 ccc|    1|          2|     3|   M|    4|    77.0|        a|    b|          4|          lorem|  lorem|\n",
      "|77.0|    a|       b|77.0|                 ccc|    1|          2|     3|   M|    4|    77.0|        a|    b|          4|          lorem|   NULL|\n",
      "|22.0| NULL|       S|7.25|Braund, Mr. Owen ...|    0|          1|     3|male|    1|     0.0|A/5 21171|   Mr|          1|           NULL|   NULL|\n",
      "+----+-----+--------+----+--------------------+-----+-----------+------+----+-----+--------+---------+-----+-----------+---------------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                name|  type|        snapshot_id|max_reference_age_in_ms|min_snapshots_to_keep|max_snapshot_age_in_ms|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                main|BRANCH|6609739537041086161|                   NULL|                 NULL|                  NULL|\n",
      "|yearly_snapshots_10y|BRANCH|6609739537041086161|           315360000000|                   10|                  NULL|\n",
      "|            EOY_2024|   TAG|6609739537041086161|             2592000000|                 NULL|                  NULL|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "\n",
      "retained last 10 snapshots (except for branches and tags)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/22 18:49:17 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the absolute paths to the Iceberg tables and JAR files\n",
    "iceberg_tables_path = \"/Users/france.cama/code/iceberg-practice/iceberg_tables\"\n",
    "iceberg_jars_path = \"/Users/france.cama/code/iceberg-practice/jars/iceberg-spark-runtime-3.5_2.12-1.5.1.jar\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg table management\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dderby.system.home=\" + iceberg_tables_path) \\\n",
    "    .config(\"spark.jars\", iceberg_jars_path) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.warehouse\", iceberg_tables_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic.history;\").show()\n",
    "\n",
    "print(\"Branches of the table. If none has been created: just the main branch is printed which points \"\n",
    "      \"at the selected version/snapshot of the table\")\n",
    "spark.sql(\"SELECT * FROM default.titanic.refs;\").show()\n",
    "\n",
    "spark.sql(\"ALTER TABLE default.titanic DROP TAG EOY_2024\")\n",
    "\n",
    "\n",
    "# the basic way the get rid of snapshots (to control metadata size and storage costs) is to use the 'expire_snapshots' procedure.\n",
    "spark.sql(\"CALL system.expire_snapshots(\" \\\n",
    "        \"table => 'default.titanic',\\\n",
    "        older_than => TIMESTAMP '2024-07-22 11:12:59.000')\")\n",
    "print(\"Done!\")\n",
    "\n",
    "# a more sophisticated way to manage the lifecycle of snapshots is to use BRANCHES and TAGS which do expires after the specified age.\n",
    "# BRANCHES are independent lineages of snapshots and point to the head of the lineage\n",
    "# TAGS can be used for retaining important historical snapshots for auditing purposes.\n",
    "# Branching and tagging can be used for handling GDPR requirements.\n",
    "# Branches can also be used as part of data engineering workflows, for enabling experimental branches for testing and validating new jobs.\n",
    "\n",
    "# -- Create a tag for the end of the year and retain it forever.\n",
    "spark.sql(\"ALTER TABLE default.titanic CREATE TAG EOY_2024 RETAIN 30 DAYS\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic VERSION AS OF 'EOY_2024'\").show(3)\n",
    "\n",
    "# -- Let's create a branch to keep 1 snapshot for year for a maximum of 10 snapshots. (GDPR use case)\n",
    "# spark.sql(\"ALTER TABLE default.titanic CREATE BRANCH yearly_snapshots_10y RETAIN 3650 DAYS WITH SNAPSHOT RETENTION 10 SNAPSHOTS\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic.refs;\").show()\n",
    "\n",
    "spark.sql(\"CALL system.expire_snapshots(\" \\\n",
    "        \"table => 'default.titanic',\\\n",
    "        retain_last => 10)\")\n",
    "print(\"retained last 10 snapshots (except for branches and tags)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8a177-0d8b-4430-bda4-378c11416333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
