{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c8a5d4-d21d-419d-9e2c-bd2a3841ed32",
   "metadata": {},
   "source": [
    "For controlling metadata size and storage costs, Iceberg provides snapshot lifecycle management procedures such as expire_snapshots and other table management techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10056d8-0bb3-4dae-b8c9-9c6ccbecc105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2024-07-22 12:23:...|6609739537041086161|1184812391625634863|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "Branches of the table. If none has been created: just the main branch is printed which points at the selected version/snapshot of the table\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                name|  type|        snapshot_id|max_reference_age_in_ms|min_snapshots_to_keep|max_snapshot_age_in_ms|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                main|BRANCH|6609739537041086161|                   NULL|                 NULL|                  NULL|\n",
      "|yearly_snapshots_10y|BRANCH|6609739537041086161|           315360000000|                   10|                  NULL|\n",
      "|            EOY_2024|   TAG|6609739537041086161|             2592000000|                 NULL|                  NULL|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "\n",
      "Done!\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+---------+-----+-----------+---------------+-------+\n",
      "| Age|Cabin|Embarked|   Fare|                Name|Parch|PassengerId|Pclass|   Sex|SibSp|Survived|   Ticket|Title|Family_Size|choose_a_column|new_col|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+---------+-----+-----------+---------------+-------+\n",
      "|77.0|    a|       b|   77.0|                 ccc|    1|          2|     3|     M|    4|    77.0|        a|    b|          4|          lorem|  lorem|\n",
      "|22.0| NULL|       S|   7.25|Braund, Mr. Owen ...|    0|          1|     3|  male|    1|     0.0|A/5 21171|   Mr|          1|           NULL|   NULL|\n",
      "|38.0|  C85|       C|71.2833|Cumings, Mrs. Joh...|    0|          2|     1|female|    1|     1.0| PC 17599|  Mrs|          1|           NULL|   NULL|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+---------+-----+-----------+---------------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                name|  type|        snapshot_id|max_reference_age_in_ms|min_snapshots_to_keep|max_snapshot_age_in_ms|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "|                main|BRANCH|6609739537041086161|                   NULL|                 NULL|                  NULL|\n",
      "|yearly_snapshots_10y|BRANCH|6609739537041086161|           315360000000|                   10|                  NULL|\n",
      "|            EOY_2024|   TAG|6609739537041086161|             2592000000|                 NULL|                  NULL|\n",
      "+--------------------+------+-------------------+-----------------------+---------------------+----------------------+\n",
      "\n",
      "retained last 10 snapshots (except for branches and tags)\n",
      "+--------------------+\n",
      "|orphan_file_location|\n",
      "+--------------------+\n",
      "+--------------------+\n",
      "\n",
      "+--------------------------+----------------------+---------------------+-----------------------+\n",
      "|rewritten_data_files_count|added_data_files_count|rewritten_bytes_count|failed_data_files_count|\n",
      "+--------------------------+----------------------+---------------------+-----------------------+\n",
      "|                         0|                     0|                    0|                      0|\n",
      "+--------------------------+----------------------+---------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the absolute paths to the Iceberg tables and JAR files\n",
    "iceberg_tables_path = \"/Users/france.cama/code/iceberg-practice/iceberg_tables\"\n",
    "iceberg_jars_path = \"/Users/france.cama/code/iceberg-practice/jars/iceberg-spark-runtime-3.5_2.12-1.5.1.jar\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg table management\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dderby.system.home=\" + iceberg_tables_path) \\\n",
    "    .config(\"spark.jars\", iceberg_jars_path) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.warehouse\", iceberg_tables_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic.history;\").show()\n",
    "\n",
    "print(\"Branches of the table. If none has been created: just the main branch is printed which points \"\n",
    "      \"at the selected version/snapshot of the table\")\n",
    "spark.sql(\"SELECT * FROM default.titanic.refs;\").show()\n",
    "\n",
    "spark.sql(\"ALTER TABLE default.titanic DROP TAG EOY_2024\")\n",
    "\n",
    "\n",
    "# the basic way the get rid of snapshots (to control metadata size and storage costs) is to use the 'expire_snapshots' procedure.\n",
    "# using expire_snapshots procedure also deletes the linked data files but it excludes the snapshots related to branches and tags.\n",
    "spark.sql(\"CALL system.expire_snapshots(\" \\\n",
    "        \"table => 'default.titanic',\\\n",
    "        older_than => TIMESTAMP '2024-07-22 11:12:59.000')\")\n",
    "print(\"Done!\")\n",
    "\n",
    "# a more sophisticated way to manage the lifecycle of snapshots is to use BRANCHES and TAGS which do expires after the specified age.\n",
    "# BRANCHES are independent lineages of snapshots and point to the head of the lineage\n",
    "# TAGS can be used for retaining important historical snapshots for auditing purposes.\n",
    "# Branching and tagging can be used for handling GDPR requirements.\n",
    "# Branches can also be used as part of data engineering workflows, for enabling experimental branches for testing and validating new jobs.\n",
    "\n",
    "# -- Create a tag for the end of the year and retain it forever.\n",
    "spark.sql(\"ALTER TABLE default.titanic CREATE TAG EOY_2024 RETAIN 30 DAYS\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic VERSION AS OF 'EOY_2024'\").show(3)\n",
    "\n",
    "# -- Let's create a branch to keep 1 snapshot for year for a maximum of 10 snapshots. (GDPR use case)\n",
    "# spark.sql(\"ALTER TABLE default.titanic CREATE BRANCH yearly_snapshots_10y RETAIN 3650 DAYS WITH SNAPSHOT RETENTION 10 SNAPSHOTS\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic.refs;\").show()\n",
    "\n",
    "\n",
    "spark.sql(\"CALL system.expire_snapshots(\" \\\n",
    "        \"table => 'default.titanic',\\\n",
    "        retain_last => 10)\")\n",
    "print(\"retained last 10 snapshots (except for branches and tags)\")\n",
    "\n",
    "# run a procedure that lists the orphan files \n",
    "spark.sql(\"CALL system.remove_orphan_files(table => 'default.titanic', dry_run => true)\").show()\n",
    "\n",
    "# Data files compaction: a large amount of data files can reduce performances for two main reasons: metadata lookup and disk retrieval.\n",
    "# if a large amount of data files exists, they can be compacted into more juicy data files with the following procedure. \n",
    "# note that there are different strategies that can be used to rewrite data files.\n",
    "spark.sql(\"CALL system.rewrite_data_files(table => 'default.titanic',  strategy => 'sort', sort_order => 'zorder(PassengerId)')\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075f8e2-a21f-445d-a00a-253a520882fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
