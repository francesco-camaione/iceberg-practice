{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e424e8-3cc0-4a93-87ab-ff2afea13dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/22 12:22:51 WARN Utils: Your hostname, MBA-Francesco.local resolves to a loopback address: 127.0.0.1; using 192.168.1.62 instead (on interface en0)\n",
      "24/07/22 12:22:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/07/22 12:22:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/22 12:22:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2024-07-22 12:22:...|2309543119036033141|6609739537041086161|               true|\n",
      "|2024-07-22 11:47:...|6609739537041086161|1184812391625634863|               true|\n",
      "|2024-07-22 11:11:...|1759033321787871743| 813399347516847428|              false|\n",
      "|2024-07-22 11:11:...| 813399347516847428|6609739537041086161|              false|\n",
      "|2024-07-22 11:11:...|6609739537041086161|1184812391625634863|               true|\n",
      "|2024-07-22 11:10:...|1184812391625634863|4619981039604578990|               true|\n",
      "|2024-07-22 11:09:...|4619981039604578990|               NULL|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "2309543119036033141 813399347516847428\n",
      "Data with new schema:\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+---------------+-------+\n",
      "| Age|Cabin|Embarked|   Fare|                Name|Parch|PassengerId|Pclass|   Sex|SibSp|Survived|          Ticket|Title|Family_Size|choose_a_column|new_col|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+---------------+-------+\n",
      "|77.0|    a|       b|   77.0|                 ccc|    1|          2|     3|     M|    4|    77.0|               a|    b|          4|          lorem|  lorem|\n",
      "|22.0| NULL|       S|   7.25|Braund, Mr. Owen ...|    0|          1|     3|  male|    1|     0.0|       A/5 21171|   Mr|          1|           NULL|   NULL|\n",
      "|38.0|  C85|       C|71.2833|Cumings, Mrs. Joh...|    0|          2|     1|female|    1|     1.0|        PC 17599|  Mrs|          1|           NULL|   NULL|\n",
      "|26.0| NULL|       S|  7.925|Heikkinen, Miss. ...|    0|          3|     3|female|    0|     1.0|STON/O2. 3101282| Miss|          0|           NULL|   NULL|\n",
      "|35.0| C123|       S|   53.1|Futrelle, Mrs. Ja...|    0|          4|     1|female|    1|     1.0|          113803|  Mrs|          1|           NULL|   NULL|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Data with old schema:\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+---------------+\n",
      "| Age|Cabin|Embarked|   Fare|                Name|Parch|PassengerId|Pclass|   Sex|SibSp|Survived|          Ticket|Title|Family_Size|choose_a_column|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+---------------+\n",
      "|77.0|    a|       b|   77.0|                 ccc|    1|          2|     3|     M|    4|    77.0|               a|    b|          4|          lorem|\n",
      "|22.0| NULL|       S|   7.25|Braund, Mr. Owen ...|    0|          1|     3|  male|    1|     0.0|       A/5 21171|   Mr|          1|           NULL|\n",
      "|38.0|  C85|       C|71.2833|Cumings, Mrs. Joh...|    0|          2|     1|female|    1|     1.0|        PC 17599|  Mrs|          1|           NULL|\n",
      "|26.0| NULL|       S|  7.925|Heikkinen, Miss. ...|    0|          3|     3|female|    0|     1.0|STON/O2. 3101282| Miss|          0|           NULL|\n",
      "|35.0| C123|       S|   53.1|Futrelle, Mrs. Ja...|    0|          4|     1|female|    1|     1.0|          113803|  Mrs|          1|           NULL|\n",
      "+----+-----+--------+-------+--------------------+-----+-----------+------+------+-----+--------+----------------+-----+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the absolute paths to the Iceberg tables and JAR files\n",
    "iceberg_tables_path = \"/Users/france.cama/code/iceberg-practice/iceberg_tables\"\n",
    "iceberg_jars_path = \"/Users/france.cama/code/iceberg-practice/jars/iceberg-spark-runtime-3.5_2.12-1.5.1.jar\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg schema evolution feature\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dderby.system.home=\" + iceberg_tables_path) \\\n",
    "    .config(\"spark.jars\", iceberg_jars_path) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.warehouse\", iceberg_tables_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sql(\"ALTER TABLE titanic DROP COLUMN new_col;\")\n",
    "\n",
    "# Add a new column to the schema\n",
    "spark.sql(\"ALTER TABLE titanic ADD COLUMN new_col string\")\n",
    "spark.sql(\"INSERT INTO default.titanic VALUES (77, 'a', 'b', 77, 'ccc', 1, 2, 3, 'M', 4, 77, 'a', 'b', 4, 'lorem', 'lorem');\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.titanic.history ORDER BY made_current_at DESC;\").show()\n",
    "\n",
    "current_snapshot_id = spark.sql(\"SELECT snapshot_id FROM default.titanic.history ORDER BY made_current_at DESC;\").first()[0]\n",
    "second_snapshot_id = spark.sql(\"SELECT snapshot_id FROM default.titanic.history ORDER BY made_current_at DESC LIMIT 1 OFFSET 3;\").first()[0]\n",
    "\n",
    "print(current_snapshot_id, second_snapshot_id )\n",
    "\n",
    "# Read the table with the new schema\n",
    "df = spark.sql(f\"SELECT * FROM titanic VERSION AS OF {current_snapshot_id};\")\n",
    "print(\"Data with new schema:\")\n",
    "df.show(5)\n",
    "\n",
    "# Read the table with the old schema\n",
    "df_old = spark.sql(f\"SELECT * FROM titanic VERSION AS OF 1184812391625634863;\")\n",
    "print(\"Data with old schema:\")\n",
    "df_old.show(5)\n",
    "\n",
    "#spark.sql(\"ALTER TABLE titanic DROP COLUMN choose_a_column;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74025246-e1a0-474c-856a-89da3a9bddb2",
   "metadata": {},
   "source": [
    "It's possible to alter the schema of the table and depending on the snapshot you want to access the schema is determined, allowing you to time travel back in time and look at data using the old table schema and data. \n",
    "In the previous cell I only showed the add column case but iceberg supports the following schema changes: \n",
    "- <strong>Add</strong> -- add a new column to the table or to a nested struct\n",
    "- <strong>Drop</strong> -- remove an existing column from the table or a nested struct\n",
    "- <strong>Rename</strong> -- rename an existing column or field in a nested struct\n",
    "- <strong>Update</strong> -- widen the type of a column, struct field, map key, map value, or list element\n",
    "- <strong>Reorder</strong> -- change the order of columns or fields in a nested struct\n",
    "\n",
    "Iceberg guarantees that schema evolution changes are independent and free of side-effects, without rewriting files. Iceberg uses unique IDs to track each column in a table. When you add a column, it is assigned a new ID so existing data is never used by mistake"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
